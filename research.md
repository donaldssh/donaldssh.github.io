---
layout: page
title: "Research"
permalink: /research/
---

I am currently doing an internship at [Samsung Research UK](https://research.samsung.com/sruk){:target="_blank"} under the supervision of [Umberto Michieli](https://umbertomichieli.github.io/){:target="_blank"} and [Mete Ozay](https://openreview.net/profile?id=~Mete_Ozay3){:target="_blank"}.

I am a third year Ph.D. student in [Information Engineering](https://phd.dei.unipd.it){:target="_blank"} at the [University of Padova](https://www.unipd.it){:target="_blank"} (Italy), under the supervision of Prof. [Pietro Zanuttigh](https://medialab.dei.unipd.it/members/pietro-zanuttigh/){:target="_blank"}. On December 2nd, 2024, I submitted the final version of my Ph.D. thesis.

From May to November 2023, I was a research intern at [Mila - Quebec AI Institute](https://mila.quebec/en/){:target="_blank"} & [Concordia University](https://www.concordia.ca/ginacody/computer-science-software-eng.html){:target="_blank"}, under the supervision of Prof. [Eugene Belilovsky](http://eugenium.github.io/){:target="_blank"}.

During my Ph.D. I worked on large-scale machine learning problems and their application to visual understanding, in particular I worked on **Federated Learning**, **Continual Learning**, **Domain Adaptation**, and **Semantic Segmentation**. 
Recently, I'm working on **Model Merging** and **Image Generation**.


<h6><a href="https://github.com/donaldssh/cv/raw/master/cv.pdf" id="download_cv" download>[Download CV]</a></h6>


### Publications


#### Preprints


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/lorarar.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> [P1]  <b>D. Shenaj</b>, O. Bohdal, M. Ozay, P. Zanuttigh, U. Michieli, "<b>LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation</b>", arXiv:2412.05148, 2024. <a href="https://arxiv.org/abs/2412.05148" class="paper_code">[paper]</a> </p>
    </td>
  </tr>
</table>


####  Conferences


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/hyper.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
 <p>[C4] G. Rizzoli*, M. Caligiuri*, <b>D. Shenaj</b>, F. Barbato, P. Zanuttigh, "<b>When Cars meet Drones: Hyperbolic Federated Learning for Source-Free Domain Adaptation in Adverse Weather</b>", IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2025.  <a href="https://arxiv.org/abs/2403.13762" class="paper_code">[paper]</a><a href="https://github.com/LTTM/HyperFLAW" class="paper_code">[code]</a> </p>
 </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/misfit.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
<p>[C3] G. Rizzoli, <b>D. Shenaj</b>, P Zanuttigh, "<b>Source-Free Domain Adaptation for RGB-D Semantic Segmentation with Vision Transformers</b>", IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Pretrain Workshop 2024. <a href="https://arxiv.org/abs/2305.14269" class="paper_code">[paper]</a></p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/LTTM/FedSpace/main/media/setup.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p>[C2] <b>D. Shenaj</b>, M. Toldo, A. Rigon, P. Zanuttigh, "<b>Asynchronous Federated Continual Learning</b>", IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), FedVision Workshop, 2023. <a href="https://arxiv.org/abs/2304.03626" class="paper_code">[paper]</a><a href="https://github.com/LTTM/FedSpace" class="paper_code">[code]</a></p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/Erosinho13/LADD/refs/heads/main/teaser.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> [C1] <b>D. Shenaj</b>*, E. Fanì*, M. Toldo, D. Caldarola, A. Tavera, U. Michieli<sup>&#8224;</sup>, M. Ciccone<sup>&#8224;</sup>, P. Zanuttigh<sup>&#8224;</sup>, B. Caputo<sup>&#8224;</sup>, “<b>Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning</b>”, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023. <a href="https://arxiv.org/abs/2210.02326" class="paper_code">[paper]</a><a href="https://github.com/Erosinho13/LADD" class="paper_code">[code]</a> </p>
    </td>
  </tr>
</table>


#### Journals


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/survey.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> [J2]  <b>D. Shenaj</b>*, G. Rizzoli*, P. Zanuttigh, "<b>Federated Learning in Computer Vision</b>", IEEE Access, 2023. <a href="https://ieeexplore.ieee.org/document/10234425" class="paper_code">[paper]</a> </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/LTTM/CCDA/main/img/architecture_ccda.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> [J1] <b>D. Shenaj</b>, F. Barbato, U. Michieli, P. Zanuttigh, "<b>Continual coarse-to-fine domain adaptation in semantic segmentation</b>", Elsevier Image and Vision Computing, 2022. <a href="https://doi.org/10.1016/j.imavis.2022.104426" class="paper_code">[paper]</a><a href="https://lttm.dei.unipd.it/paper_data/CCDA/" class="paper_code">[webpage]</a><a href="https://github.com/LTTM/CCDA" class="paper_code">[code]</a> </p>
    </td>
  </tr>
</table>

<sup>\*</sup> Equal contribution. <sup>&#8224;</sup> Equal supervision.
##### Bachelor and Master Thesis  

[T2] D. Shenaj, "Coarse-to-Fine Learning for Semantic Segmentaion across Multiple Domains", MS thesis in ICT for Internet and Multimedia, University of Padova, September 2021.


[T1] D. Shenaj, "Implementation and analysis of a vehicle counter system with Python and OpenCV", BS thesis in Electronics Engineering for Energy and Information, University of Bologna, October 2019.
