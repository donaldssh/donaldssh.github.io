---
layout: page
title: "Research"
permalink: /research/
---

I am a Postdoctoral Researcher at the [University of Pisa](https://www.unipi.it){:target="_blank"}, working in [Davide Bacciu](https://pages.di.unipi.it/bacciu/){:target="_blank"}’s group. I am part of the [CoEvolution Project](https://coevolution-project.eu/){:target="_blank"} for safe and trusthworthy AI.

I obtained my Ph.D. at the [University of Padova](https://www.unipd.it){:target="_blank"}, under the guidance of Prof. [Pietro Zanuttigh](https://medialab.dei.unipd.it/members/pietro-zanuttigh/){:target="_blank"}. Before that, I earned a Master Degree from the same University, and a Bachelor Degree from the [University of Bologna](https://www.unibo.it/en){:target="_blank"}, both with honors.

My academic journey has been marked by collaborations with globally renowned institutions. From October 2024 to April 2025 I as a research intern at [Samsung Research UK](https://research.samsung.com/sruk){:target="_blank"} under the supervision of [Umberto Michieli](https://umbertomichieli.github.io/){:target="_blank"} and [Mete Ozay](https://openreview.net/profile?id=~Mete_Ozay3){:target="_blank"}. From May 2023 to November 2023, I was a research intern at [Mila - Quebec AI Institute](https://mila.quebec/en/){:target="_blank"} & [Concordia University](https://www.concordia.ca/ginacody/computer-science-software-eng.html){:target="_blank"}, working with Prof. [Eugene Belilovsky](http://eugenium.github.io/){:target="_blank"}.

During my Ph.D., I addressed fundamental limitations of machine learning models for visual understanding, specifically their challenges in adapting to dynamic, real-world conditions, learning continuosly over time and from decentralized data sources,
My research explored these challenges through three emerging paradigms: domain adaptation, continual learning, and federated learning.

Building on this foundation of adaptability and decentralized learning, my current work focuses on personalized generative AI, where I explore how **model merging**, **image generation**, and **large language models (LLMs)** can be combined to enable personalized and adaptive AI systems.

I am always open to new collaborations! Email me, if you would like to discuss or catch up at a conference.

<h6><a href="https://github.com/donaldssh/cv/raw/master/cv.pdf" id="download_cv" download>[Download CV]</a></h6>

### Reviewer
CVPR 2026, ICCV 2025, CVPR 2025 (Outstanding Reviewer), AAAI 2025, ICLR Workshops 2025, CVPR Workshops 2025, WACV 2025, IEEE TPAMI, IEEE TMM, Pattern Recognition, CVIU, MMSP 2024, ICML 2023 Workshops, ICPR 2022, Harms and Risks of AI in the Military (HRAIM)

### Publications


#### Preprints


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/kmerge.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>K-Merge: Online Continual Merging of Adapters for On-device Large Language Models</b> <br>
      <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, O. Bohdal, T. Ceritli, M. Ozay, P. Zanuttigh, U. Michieli <br>
       under review, 2025.<br>
      <a href="https://arxiv.org/abs/2510.13537" class="link_research">[paper]</a>
    </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/fedpromo.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>FedPromo: Federated Lightweight Proxy Models at the Edge Bring New Domains to Foundation Models</b> <br>
      M. Caligiuri, F. Barbato, <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, U. Michieli, P. Zanuttigh<br>
       under review, 2025.<br>
      <a href="https://arxiv.org/abs/2508.03356" class="link_research">[paper]</a><a href="https://github.com/LTTM/FedPromo" class="link_research">[code]</a>
    </p>
    </td>
  </tr>
</table>


####  Conferences


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://donaldssh.github.io/LoRA.rar/images/teaser_iccv.jpg" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation</b> <br>
      <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, O. Bohdal, M. Ozay, P. Zanuttigh, U. Michieli <br>
       IEEE/CVF International Conference on Computer Vision (ICCV), 2025.<br>
      <a href="https://arxiv.org/abs/2412.05148" class="link_research">[paper]</a><a href="https://donaldssh.github.io/LoRA.rar" class="link_research">[website]</a><a href="https://github.com/donaldssh/LoRA.rar" class="link_research">[code]</a><a href="https://www.youtube.com/watch?v=S0ogyrwZLxU" class="link_research">[video]</a>
    </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/ALT.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Adaptive Local Training in Federated Learning</b> <br>
        <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, E. Belilovsky, P. Zanuttigh  <br>
       International Conference on Learning Representations (ICLR), 2025, MCDC Workshop, and EUSIPCO 2025.<br>
      <a href="https://openreview.net/forum?id=EAMnemlXB2" class="link_research">[paper]</a><a href="https://github.com/LTTM/ALT" class="link_research">[code]</a>
    </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/hyper.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>When Cars meet Drones: Hyperbolic Federated Learning for Source-Free Domain Adaptation in Adverse Weather</b> <br>
        G. Rizzoli*, M. Caligiuri*, <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, F. Barbato, P. Zanuttigh  <br>
       IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2025 (oral).<br>
      <a href="https://arxiv.org/abs/2403.13762" class="link_research">[paper]</a><a href="https://github.com/LTTM/HyperFLAW" class="link_research">[code]</a> 
    </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/misfit.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Source-Free Domain Adaptation for RGB-D Semantic Segmentation with Vision Transformers</b> <br> 
       G. Rizzoli, <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, P Zanuttigh <br> 
       IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Pretrain Workshop 2024 (oral). <br> 
        <a href="https://arxiv.org/abs/2305.14269" class="link_research">[paper]</a>
    </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/LTTM/FedSpace/main/media/setup.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Asynchronous Federated Continual Learning</b> <br>
     <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, M. Toldo, A. Rigon, P. Zanuttigh <br>
     IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), FedVision Workshop, 2023 (oral). <br>
      <a href="https://arxiv.org/abs/2304.03626" class="link_research">[paper]</a><a href="https://github.com/LTTM/FedSpace" class="link_research">[code]</a>
      </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/Erosinho13/LADD/refs/heads/main/teaser.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning</b> <br>
     <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>*, E. Fanì*, M. Toldo, D. Caldarola, A. Tavera, U. Michieli<sup>&#8224;</sup>, M. Ciccone<sup>&#8224;</sup>, P. Zanuttigh<sup>&#8224;</sup>, B. Caputo<sup>&#8224;</sup> <br>
      IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023 (oral). <br>
      <a href="https://arxiv.org/abs/2210.02326" class="link_research">[paper]</a><a href="https://github.com/Erosinho13/LADD" class="link_research">[code]</a> 
      </p>
    </td>
  </tr>
</table>


#### Journals


<table style="border-collapse: collapse; border-spacing: 0 10px; width: 100%;">
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/donaldssh/donaldssh.github.io/master/res_thumbs/survey.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Federated Learning in Computer Vision</b> <br>
    <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>*, G. Rizzoli*, P. Zanuttigh <br>
     IEEE Access, 2023. <br>
      <a href="https://ieeexplore.ieee.org/document/10234425" class="link_research">[paper]</a>
      </p>
    </td>
  </tr>
  <tr>
    <td style="border: none; width: 20%; text-align: left; vertical-align: top; padding-right: 4%;">
      <img src="https://raw.githubusercontent.com/LTTM/CCDA/main/img/architecture_ccda.png" alt="ABS" style="width: 100%;">
    </td>
    <td style="border: none; width: 70%; text-align: left;">
    <p> <b>Continual coarse-to-fine domain adaptation in semantic segmentation</b> <br>
    <a href="https://scholar.google.com/citations?user=hK8OlqkAAAAJ" class="link_research">D. Shenaj</a>, F. Barbato, U. Michieli, P. Zanuttigh <br>
       Elsevier Image and Vision Computing, 2022. <br>
     <a href="https://doi.org/10.1016/j.imavis.2022.104426" class="link_research">[paper]</a><a href="https://lttm.dei.unipd.it/paper_data/CCDA/" class="link_research">[website]</a><a href="https://github.com/LTTM/CCDA" class="link_research">[code]</a>
     </p>
    </td>
  </tr>
</table>

<sup>\*</sup> Equal contribution. <sup>&#8224;</sup> Equal supervision.
##### Ph.D., Master's and Bachelor's Thesis  

[T3] D. Shenaj, "Morphing Distributed and Transfer Learning Paradigms for Visual Understanding", Ph.D thesis in Information Engineering, University of Padova, (Submitted) December 2024.


[T2] D. Shenaj, "Coarse-to-Fine Learning for Semantic Segmentaion across Multiple Domains", MS thesis in ICT for Internet and Multimedia, University of Padova, September 2021.


[T1] D. Shenaj, "Implementation and analysis of a vehicle counter system with Python and OpenCV", BS thesis in Electronics Engineering for Energy and Information, University of Bologna, October 2019.
