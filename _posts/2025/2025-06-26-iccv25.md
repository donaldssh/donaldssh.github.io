---
layout: post
title:  "Paper accepted at ICCV 2025"
date:   2025-06-26 12:00:00
categories:
    - blog
tags:
    - paper
---

ğŸš€Exciting news, ğ—Ÿğ—¼ğ—¥ğ—”.ğ—¿ğ—®ğ—¿ has been accepted to ICCV 2025, which will be held in October in HawaiiğŸŒˆ.

In this work, we:

âœ¨ Pre-trained a hypernetwork on a dataset of LoRAs, to enable zero-shot merging of unseen content-style LoRAs.

ğŸ¤ Proposed a new evaluation protocol with MARSÂ², a new metric based on Multimodal Large Language Models, for better content-style fidelity assessment, which aligns closely with user preferences.

âš¡ï¸ Achieved improved generation fidelity and footprints compared to ZipLoRA (ECCV 2024). LoRA.rar is 4000x faster in the merging process, uses 3x fewer parameters than a single subject-style combination of ZipLoRA, and outperforms the current state of the art in both content and style fidelity, as validated by MLLM assessments and human evaluations.

Huge thanks to the team: Ondrej Bohdal, Mete Ozay, Pietro Zanuttigh, and Umberto Michieli.


ğŸ“œ Preprint: <https://arxiv.org/abs/2412.05148>{:target="_blank"}

ğŸ’» Code: <https://github.com/donaldssh/LoRA.rar>{:target="_blank"}


<div style="position: relative; width: 100%; padding-bottom: 56.25%; height: 0; overflow: hidden; margin: 1em 0;">
  <iframe 
    src="https://www.youtube.com/embed/FfExWgcgNbQ?si=3OGDPZ55qXJZ0q7w" 
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: 0;" 
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
    allowfullscreen 
    title="YouTube video player" 
    referrerpolicy="strict-origin-when-cross-origin">
  </iframe>
</div>
